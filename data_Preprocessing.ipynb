import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns

# Load the dataset
data = pd.read_csv('Data.csv')

# Split the dataset
features = data.iloc[:, :-1].values
labels = data.iloc[:, -1].values
print(features)
print(labels)

# Handle missing data
from sklearn.impute import SimpleImputer
missing_val_imputer = SimpleImputer(missing_values=np.nan, strategy="mean")
missing_val_imputer.fit(features[:, 1:3])
features[:, 1:3] = missing_val_imputer.transform(features[:, 1:3])
print(features)

# Encoding categorical data
from sklearn.compose import ColumnTransformer
from sklearn.preprocessing import OneHotEncoder
column_transformer = ColumnTransformer(transformers=[('cat_encoder', OneHotEncoder(), [0])], remainder='passthrough')
features = np.array(column_transformer.fit_transform(features))
print(features)

# Encode the labels
from sklearn.preprocessing import LabelEncoder
label_encoder = LabelEncoder()
labels = label_encoder.fit_transform(labels)
print(labels)

# Split data into training and testing sets
from sklearn.model_selection import train_test_split
X_train, X_test, Y_train, Y_test = train_test_split(features, labels, test_size=0.2, random_state=1)
print(X_train)
print(X_test)
print(Y_train)
print(Y_test)

# Feature scaling
from sklearn.preprocessing import StandardScaler
scaler = StandardScaler()
X_train[:, 3:] = scaler.fit_transform(X_train[:, 3:])
X_test[:, 3:] = scaler.transform(X_test[:, 3:])
print(X_train)
print(X_test)
